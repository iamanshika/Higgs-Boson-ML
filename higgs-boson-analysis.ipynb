{"metadata":{"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install dtreeviz","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nfrom matplotlib import rcParams\nfrom collections import Counter\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier,VotingClassifier\nfrom sklearn.naive_bayes import GaussianNB,MultinomialNB\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.naive_bayes import BernoulliNB\nfrom xgboost import XGBClassifier\nfrom sklearn.preprocessing import LabelEncoder,normalize,MinMaxScaler,Normalizer\nfrom sklearn.metrics import f1_score\nfrom sklearn.model_selection import train_test_split,cross_val_score\nfrom sklearn.metrics import confusion_matrix,roc_auc_score,roc_curve\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import plot_confusion_matrix\nfrom sklearn.inspection import permutation_importance\nimport seaborn as sns\nfrom imblearn.over_sampling import SMOTE\n%matplotlib inline\nimport scipy as sp\nimport matplotlib.pyplot as plt\n\nimport tensorflow as tf\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom sklearn.metrics import accuracy_score, roc_auc_score\nfrom tensorflow.keras.layers import Input, Dense\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras import models\nfrom sklearn.linear_model import LogisticRegression\nimport xgboost as xgb\n\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.callbacks import EarlyStopping\n\nimport pandas as pd\nimport seaborn as sns\nfrom itertools import combinations\nfrom IPython.display import display, HTML\nfrom dtreeviz.trees import dtreeviz\n\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Defining two functions that are used to get a report of our datasets**","metadata":{}},{"cell_type":"code","source":"def pretty_print(df):\n    return display( HTML( df.to_html().replace(\"\\\\n\",\"<br>\") ) )\ndef tbl_report(tbl, cols=None, card=10):\n    print(\"Table Shape\", tbl.shape)\n    dtypes = tbl.dtypes\n    nulls = []\n    uniques = []\n    numuniques = []\n    vcs = []\n    for col in dtypes.index:\n        n = tbl[col].isnull().sum()\n        nulls.append(n)\n        strdtcol = str(dtypes[col])\n        #if strdtcol == 'object' or strdtcol[0:3] == 'int' or strdtcol[0:3] == 'int':\n        #print(strdtcol)\n        uniqs = tbl[col].unique()\n        uniquenums = uniqs.shape[0]\n        if uniquenums < card: # low cardinality\n            valcounts = pd.value_counts(tbl[col], dropna=False)\n            vc = \"\\n\".join([\"{}:{}\".format(k,v) for k, v in valcounts.items()])\n        else:\n            vc='HC' # high cardinality\n        uniques.append(uniqs)\n        numuniques.append(uniquenums)\n        vcs.append(vc)\n    nullseries = pd.Series(nulls, index=dtypes.index)\n    uniqueseries = pd.Series(uniques, index=dtypes.index)\n    numuniqueseries = pd.Series(numuniques, index=dtypes.index)\n    vcseries = pd.Series(vcs, index=dtypes.index)\n    df = pd.concat([dtypes, nullseries, uniqueseries, numuniqueseries, vcseries], axis=1)\n    df.columns = ['dtype', 'nulls', 'uniques', 'num_uniques', 'value_counts']\n    if cols:\n        return pretty_print(df[cols])\n    return pretty_print(df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Loading and Reading Datasets**","metadata":{}},{"cell_type":"code","source":"#Loading train set and loading test set\ntrain = pd.read_csv(\"/kaggle/input/higgs-boson/training.zip\")\ntest = pd.read_csv(\"/kaggle/input/higgs-boson/test.zip\")\n\n#EventID is identifier - making it an index in both the sets\ntrain.set_index('EventId',inplace = True)\ntest.set_index('EventId',inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Looking at top 5 rows in train\ntrain.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Looking at training set info \ntbl_report(train, cols=['dtype', 'nulls', 'num_uniques', 'value_counts'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Looking at the numerical descriptions\ntrain.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Looking at top 5 rows in test\ntest.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Looking at test info\ntbl_report(test, cols=['dtype', 'nulls', 'num_uniques', 'value_counts'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Looking at statistical description of test\ntest.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Exploratory Data Analysis**\n","metadata":{}},{"cell_type":"code","source":"#Splitting into X and y\nX = train.drop(['Weight','Label'],axis=1)\ny = pd.factorize(train['Label'])[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Let us look at the Class Ratio in our dataset.","metadata":{}},{"cell_type":"code","source":"#Let's see the count of each class in our label\nplt.figure(figsize=(10,8))\nax = sns.countplot(train['Label']);\nfor p in ax.patches:\n        ax.annotate('{:d}'.format(p.get_height()), (p.get_x()+0.3, p.get_height()+5));","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Looks like we do indeed have an imbalanced dataset. Considering this, accuracy would not be a good metric of performance. F1 score would be a better fit.","metadata":{}},{"cell_type":"markdown","source":"## Finding distribution of each Feature","metadata":{}},{"cell_type":"code","source":"#Plotting Distribution of each feature\nfig=plt.figure(figsize=(30,40))\n\nfor i in range(np.shape(train)[1]-1):\n    ax = fig.add_subplot(8,4,i+1)\n    ax = sns.distplot(train.iloc[:,i], color = 'dodgerblue')\n    ax.set_title(\"Feature \"+ train.columns[i] +\" distribution\")\n    ax.legend()\nfig.tight_layout();","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Univariate Analysis**","metadata":{}},{"cell_type":"markdown","source":"### Finding the distribution of Data Per Class","metadata":{}},{"cell_type":"code","source":"#Plotting Distribution of features per class\nfig=plt.figure(figsize=(30,40))\n\nfor i in range(np.shape(train)[1]-2):\n    ax = fig.add_subplot(6,5,i+1)\n    ax = sns.distplot(train[train['Label'] == 's'].iloc[:,i],label=\"Class S\", color = \"blue\")\n    ax = sns.distplot(train[train['Label'] == 'b'].iloc[:,i],label=\"Class B\", color = \"grey\")\n    ax.set_title(\"Feature \"+ train.columns[i] +\" distribution per class\")\n    ax.legend()\nfig.tight_layout();","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Bivariate Analysis**","metadata":{}},{"cell_type":"markdown","source":"### Finding highly correlated Features - and printing the pairs of highly correlated features with threshold of 0.85","metadata":{}},{"cell_type":"code","source":"train.corr().style.background_gradient(cmap='Blues')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Printing out the highly correlated features along with their correlation","metadata":{}},{"cell_type":"code","source":"#List to store the features with high correlation as tuples\nfeat=[]\n#Setting a threshold of 0.9 of correlation\nthreshold=0.9\ncorrelation=X.corr()\nfor i in X.columns:\n    temp=correlation[i]\n    #Finding the correlated features greater than the threshold\n    corr_features=temp[(abs(temp)>threshold) & (temp.index!=i)].index.values\n    #Adding the correlated features into a list keeping in mind that there is only one occurrence of the feature combination\n    if(len(corr_features)!=0):\n        for j in corr_features:\n            features=(i,j)\n        \n            if(len(feat)==0):\n                feat.append(features)\n            else:\n                count=len(feat)\n                for x in feat:\n                    if set(x) != set(features):\n                        count-=1  \n                    else:\n                        break\n                if(count==0):\n                    feat.append(features)\n                #[feat.append(features) for x in feat if not (set(x)==set(features))]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"The highly correlated features are given below\")\nfor i in feat:\n    corr=correlation[i[0]][i[1]]\n    print('Features '+i[0]+' and '+i[1]+' are correlated with a correlation index of '+ str(np.round(corr,2)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Getting the Data Ready**","metadata":{}},{"cell_type":"markdown","source":"Since we have an imbalanced dataset, we are using SMOTE for upsampling and downsampling our dataset.","metadata":{}},{"cell_type":"markdown","source":"## A) Dropping Correlated Features","metadata":{}},{"cell_type":"code","source":"count = {}\nfor i, j in feat:\n    if i in count.keys():\n        count[i]+= 1\n    else:\n        count[i] = 1\n    if j in count.keys():\n        count[j]+= 1\n    else:\n        count[j] = 1\nfor k, v in count.items():\n    if v > 2:\n        X.drop(k, axis = 1, inplace = True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## B) SMOTE Technique","metadata":{}},{"cell_type":"code","source":"counter = Counter(pd.DataFrame(y))\nprint('Before', counter)\n\nsmt = SMOTE()\n\n#oversampling using SMOTE\nX_sm, y_sm = smt.fit_resample(X,y)\n\ncounter = Counter(y_sm)\nprint('After', counter)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"temp_df = pd.concat([X_sm,pd.DataFrame(y_sm,columns=['Label'])],axis=1)\n\nf, axes = plt.subplots(figsize=(15, 10), dpi=100)\nplt.subplot(121)\nsns.despine()\nsns.scatterplot(x=temp_df['PRI_met_sumet'], y=temp_df['DER_pt_ratio_lep_tau'], hue = temp_df['Label'], data=temp_df)\nplt.title('Resampling with SMOTE', fontsize=14);\n\nplt.subplot(122)\nsns.despine()\nsns.scatterplot(x=train['PRI_met_sumet'], y=train['DER_pt_ratio_lep_tau'], hue = train['Label'], data=train)\nplt.title('No resampling', fontsize=14);","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Creation of a Baseline Model**","metadata":{}},{"cell_type":"code","source":"#Storing Categorical and Continuous Variables\ncat_vars = ['PRI_jet_num']\ncont_vars = np.array(train.drop(['PRI_jet_num','Weight','Label'],axis=1).columns)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Utility Functions to make Model building and Cross-validation easier.","metadata":{}},{"cell_type":"code","source":"def cv_optimize(clf, parameters, X, y, n_jobs=1, n_folds=5, score_func=None):\n    if score_func:\n        print(\"SCORE FUNC\", score_func)\n        gs = GridSearchCV(clf, param_grid=parameters, cv=n_folds, n_jobs=n_jobs, scoring=score_func)\n    else:\n        gs = GridSearchCV(clf, param_grid=parameters, n_jobs=n_jobs, cv=n_folds)\n    gs.fit(X, y)\n    print(\"BEST\", gs.best_params_, gs.best_score_)\n    best = gs.best_estimator_\n    return best\n\ndef do_classify(clf, parameters, indf,y,score_func, n_folds=5, n_jobs=1):\n    \n    X = indf\n    y = y\n    \n    Xtrain,Xtest,ytrain,ytest = train_test_split(X,y,train_size=0.8,random_state=214)\n    \n    clf = cv_optimize(clf, parameters, Xtrain, ytrain, n_jobs=n_jobs, n_folds=n_folds, score_func=score_func)\n    \n    clf = clf.fit(Xtrain, ytrain)\n    \n    training_accuracy = clf.score(Xtrain, ytrain)\n    \n    test_accuracy = clf.score(Xtest, ytest)\n    print()\n    print()\n    print(\"############# Based On Standard Predict ################\")\n    print(\"Accuracy on training data: %0.2f\" % (training_accuracy))\n    print(\"Accuracy on test data:     %0.2f\" % (test_accuracy))\n    print()\n    print(confusion_matrix(ytest, clf.predict(Xtest)))\n    print(\"########################################################\")\n    print()\n    \n    plot_confusion_matrix(clf,Xtest,ytest,cmap=\"Blues\")\n    return clf, Xtrain, ytrain, Xtest,ytest\n\ndef p_importance(model, cols, fi, fistd = 0):\n    return pd.DataFrame({'features':cols, 'importance':fi, 'importance_std': fistd}\n                       ).sort_values('importance', ascending=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Setting up Pipeline for Baseline Logistic Regression Model","metadata":{}},{"cell_type":"code","source":"# Set Up Normalization\nnormalize = Normalizer()\n\n# Set up One Hot Encoding of Target Variable\noh = OneHotEncoder()\n\n# Continuous Variables Neet to be normalized\ncont_pipe = Pipeline([('normalize', normalize)])\n\n# Categorical variables need to be one hot encoded\ncat_pipe = Pipeline([('onehot', oh)])\n\n# Combine both into a transformer\ntransformers = [('cont', cont_pipe, cont_vars), ('cat', cat_pipe, cat_vars)]\n\n# Apply transformer to relevant columns. Nothing will be done for the rest\nct = ColumnTransformer(transformers=transformers, remainder=\"passthrough\")\n\n# Create a pipeline so that we are not leaking data from validation to train in the individual folds\npipe_lr = Pipeline(steps=[('ct', ct), ('model', LogisticRegression(max_iter=10000, penalty='l2'))])\n\n# In paramgrid we dont use C but use model__C corresponding to the name in the pipeline\nparamgrid_lr = dict(model__C=[1000, 100, 0.1])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now we train our model. Our do_classify takes care of subsetting the data and pickinging up the target variable.We score using the AUC on the validation sets.","metadata":{}},{"cell_type":"code","source":"lr, X_train, y_train, X_test, y_test = do_classify(pipe_lr, paramgrid_lr, X_sm, y_sm, score_func='roc_auc')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Setting up Pipeline for Random Forest Classifier","metadata":{}},{"cell_type":"code","source":"# Create a pipeline so that we are not leaking data from validation to train in the individual folds\npipe_rf = Pipeline(steps=[('ct', ct), ('rf', RandomForestClassifier())])\nparamgrid_rf = { 'rf__max_features': ['auto', 'sqrt'],\n  'rf__max_depth': [5,10, 20, None], \n  'rf__min_samples_split': [2, 5, 10], \n  'rf__min_samples_leaf': [1, 2, 4],\n  'rf__bootstrap': [True, False]}\n\nrf, X_train, y_train, X_test, y_test = do_classify(pipe_rf, paramgrid_rf, X_sm, y_sm, score_func='roc_auc')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Setting up Pipeline for Decision Tree Classifier","metadata":{}},{"cell_type":"code","source":"# Create a pipeline so that we are not leaking data from validation to train in the individual folds\npipe_dt = Pipeline(steps=[('ct', ct), ('dt', DecisionTreeClassifier(random_state=142))])\nparamgrid_dt = {'dt__max_depth':range(1,9),'dt__min_samples_leaf':range(3,5),'dt__criterion':['gini']}\n\n\nclf, Xtrain, ytrain, Xtest,ytest = do_classify(pipe_dt, paramgrid_dt,X,y,'roc_auc',n_folds=5,n_jobs=-1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"colors = [None, None,['red','blue'],]\ndt_viz = dtreeviz(DecisionTreeClassifier(random_state=142), X,y,\n               feature_names = X.columns,\n               target_name = 'Label', class_names= ['S','B']\n              ,orientation = 'TD',\n               colors={'classes':colors},\n               label_fontsize=12,\n               ticks_fontsize=10,\n               )\n\ndt_viz.save(\"DecisionTreeClassifier.svg\")\n\ndt_viz","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dimp = permutation_importance(DecisionTreeClassifier(random_state=142),Xtest,ytest)\nddf = p_importance(DecisionTreeClassifier(random_state=142),list(X.columns),dimp['importances_mean'],dimp['importances_std']).iloc[:10]\n\nfig,ax=plt.subplots(figsize=(17,10))\nsns.barplot(data=ddf,x='features',y='importance',label='Decision_importances',ax=ax)\nplt.xticks(rotation='45')\nplt.title(\"Bar plot of Importances for Decision Tree Model\");","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Trying out Boosting Models","metadata":{}},{"cell_type":"code","source":"Xtrain,Xtest,ytrain,ytest = train_test_split(X , y ,train_size=0.8)\n\ndtrain = xgb.DMatrix(Xtrain, label=ytrain)\ndvalid = xgb.DMatrix(Xtest, label=ytest)\n\nxgb_pars = {'min_child_weight': 100, \n            'eta': 0.04, \n            'colsample_bytree': 0.8, \n            'max_depth': 100,\n            'subsample': 0.75, \n            'lambda': 2, \n            'nthread': -1, \n            'booster' : \n            'gbtree', \n            'silent': 1, \n            'gamma' : 0,\n            'eval_metric': 'mae', \n            'objective': 'reg:linear'}    \n\nboost = xgb.train(xgb_pars, dtrain, 500, maximize=False, verbose_eval=15) \n\ny_pred = clf3.predict(dvalid)\ny_pred = [1 if y>0.5 else 0 for y in y_pred]\n\nprint(classification_report(ytest,y_pred))\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Plotting and Comparing ROC Curves**","metadata":{}},{"cell_type":"code","source":"def make_roc(name, clf, ytest, xtest, ax=None, labe=5,  proba=True, skip=0, initial = False):\n    if not ax:\n        ax=plt.gca()\n    if proba:\n        fpr, tpr, thresholds=roc_curve(ytest, clf.predict_proba(xtest)[:,1])\n    else:\n        fpr, tpr, thresholds=roc_curve(ytest, clf.decision_function(xtest))\n    roc_auc = auc(fpr, tpr)\n    if skip:\n        l=fpr.shape[0]\n        ax.plot(fpr[0:l:skip], tpr[0:l:skip], '.-', lw=2, alpha=0.4, label='ROC curve for %s (area = %0.2f)' % (name, roc_auc))\n    else:\n        ax.plot(fpr, tpr, '.-', lw=2, alpha=0.4, label='ROC curve for %s (area = %0.2f)' % (name, roc_auc))\n    label_kwargs = {}\n    label_kwargs['bbox'] = dict(\n        boxstyle='round,pad=0.3', alpha=0.2,\n    )\n    for k in range(0, fpr.shape[0],labe):\n        #from https://gist.github.com/podshumok/c1d1c9394335d86255b8\n        threshold = str(np.round(thresholds[k], 2))\n        ax.annotate(threshold, (fpr[k], tpr[k]), **label_kwargs)\n    if initial:\n        ax.plot([0, 1], [0, 1], 'k--')\n        ax.set_xlim([0.0, 1.0])\n        ax.set_ylim([0.0, 1.05])\n        ax.set_xlabel('False Positive Rate')\n        ax.set_ylabel('True Positive Rate')\n        ax.set_title('ROC')\n    ax.legend(loc=\"lower right\")\n    return ax","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"make_roc('logistic', lr, ytest ,xtest, ax=ax, labe=10,  proba=True, skip=16300, initial = False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"make_roc('randomForest', rf,ytest ,Xtest, ax=ax, labe=10,  proba=True, skip=16300, initial = False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"make_roc('decisionTree', dt,ytest ,Xtest, ax=ax, labe=10,  proba=True, skip=16300, initial = False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"make_roc('xgbboost', boost,ytest ,Xtest, ax=ax, labe=10,  proba=True, skip=16300, initial = False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Self-supervised learning in Tabular Domain using VIME**","metadata":{}},{"cell_type":"code","source":"#Setting Initial hyperparameters\n# Experimental parameters\nlabel_no = 1000  \nmodel_sets = ['logit','xgboost','mlp']\n  \n# Hyper-parameters\np_m = 0.3\nalpha = 0.01\nK = 4\nbeta = 1.0\nlabel_data_rate = 0.6\n\n# Metric\nmetric = 'acc'\n  \n# Define output\nresults = np.zeros([len(model_sets)+2])  ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Scaling data\nscaler = StandardScaler()\nX_sm = scaler.fit_transform(X_sm)\n\n#Encoding Data\ny_sm = np.where(y_sm == 'b',1,0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Splitting into unlabelled data and defining Utility functions","metadata":{}},{"cell_type":"code","source":"#Splitting X and y into train and test \nx_train_, x_test_, y_train_, y_test_ = train_test_split(X_sm, y_sm, train_size=0.7, random_state=123)\n\n#Spillting into unlabelled and labelled\nidx = np.random.permutation(len(y_train))\n\n# Label data : Unlabeled data = label_data_rate:(1-label_data_rate)\nlabel_idx = idx[:int(len(idx)*label_data_rate)]\nunlab_idx = idx[int(len(idx)*label_data_rate):]\n\n# Unlabeled data\nx_unlab = x_train.iloc[unlab_idx, :]\n\n# Labeled data\nx_train = x_train.iloc[label_idx, :]  \ny_train = y_train[label_idx, :]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Defining our Mask Generator\n![image.png](attachment:image.png)\n","metadata":{}},{"cell_type":"code","source":"#Mask Generator\ndef mask_generator (p_m, x):\n    mask = np.random.binomial(1, p_m, x.shape)\n    return mask","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Defining our Pre-text Generator","metadata":{}},{"cell_type":"code","source":"#Pre-text Generator\ndef pretext_generator (m, x):  \n    \"\"\"Generate corrupted samples.\n\n    Args:\n    m: mask matrix\n    x: feature matrix\n\n    Returns:\n    m_new: final mask matrix after corruption\n    x_tilde: corrupted feature matrix\n    \"\"\"\n\n    # Parameters\n    no, dim = x.shape  \n    \n    # Randomly (and column-wise) shuffle data\n    x_bar = np.zeros([no, dim])\n    \n    for i in range(dim):\n        idx = np.random.permutation(no)\n        x_bar[:, i] = x.iloc[idx, i]\n\n    # Corrupt samples\n    x_tilde = x * (1-m) + x_bar * m  \n    \n    # Define new mask matrix\n    m_new = 1 * (x != x_tilde)\n\n    return m_new, x_tilde","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#MLP\ndef mlp(x_train, y_train, x_test, parameters): \n\n    # Convert labels into proper format\n    if len(y_train.shape) == 1:\n        no = len(y_train)\n        dim = len(np.unique(y_train))\n\n        # Define output\n        matrix = np.zeros([no,dim])\n\n        # Convert vector to matrix\n        for i in range(dim):\n            idx = np.where(y_train == i)\n            matrix[idx, i] = 1\n\n        y_train = matrix\n\n    # Divide training and validation sets (9:1)\n    idx = np.random.permutation(len(x_train[:, 0]))\n    train_idx = idx[:int(len(idx)*0.9)]\n    valid_idx = idx[int(len(idx)*0.9):]\n\n    # Validation set\n    x_valid = x_train[valid_idx, :]\n    y_valid = y_train[valid_idx, :]\n\n    # Training set\n    x_train = x_train[train_idx, :]\n    y_train = y_train[train_idx, :]  \n\n    # Define network parameters\n    hidden_dim = parameters['hidden_dim']\n    epochs_size = parameters['epochs']\n    act_fn = parameters['activation']\n    batch_size = parameters['batch_size']\n\n    # Define basic parameters\n    data_dim = len(x_train[0, :])\n    label_dim = len(y_train[0, :])\n\n    # Build model\n    model = Sequential()\n    model.add(Dense(hidden_dim, input_dim = data_dim, activation = act_fn))\n    model.add(Dense(hidden_dim, activation = act_fn))\n    model.add(Dense(hidden_dim, activation = act_fn))\n    model.add(Dense(hidden_dim, activation = act_fn))\n    model.add(Dense(label_dim, activation = 'sigmoid'))\n\n    model.compile(loss = 'binary_crossentropy', optimizer='adam', \n                metrics = ['acc'])\n\n    es = EarlyStopping(monitor='val_loss', mode = 'min', \n                     verbose = 1, restore_best_weights=True, patience=50)\n\n    # Fit model on training dataset\n    history = model.fit(x_train, y_train, validation_data = (x_valid, y_valid), \n            epochs = epochs_size, batch_size = batch_size, \n            verbose = 0, callbacks=[es])\n\n    # Predict on x_test\n    y_test_hat = model.predict(x_test)\n    \n    # evaluate model\n    _, acc = model.evaluate(x_test, y_test, verbose=0)\n    \n    return y_test_hat, history, acc","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Encoder\n\n# Parameters\n_, dim = x_unlab.shape\nepochs = 30\nbatch_size = 128\n\n# Build model  \ninputs = Input(shape=(dim,))\n\n# Encoder  \nh = Dense(int(dim), activation='relu')(inputs)  \n\n# Mask estimator\noutput_1 = Dense(dim, activation='sigmoid', name = 'mask')(h)  \n\n# Feature estimator\noutput_2 = Dense(dim, activation='sigmoid', name = 'feature')(h)\n\nmodel = Model(inputs = inputs, outputs = [output_1, output_2])\n\nmodel.compile(optimizer='adam',\n            loss={'mask': 'binary_crossentropy', \n                  'feature': 'mean_squared_error'},\n            loss_weights={'mask':1, 'feature':alpha})\n\n# Generate corrupted samples\nm_unlab = mask_generator(p_m, x_unlab)\nm_label, x_tilde = pretext_generator(m_unlab, x_unlab)\n\n# Fit model on unlabeled data\nencoder_history = model.fit(x_tilde, {'mask': m_label, 'feature': x_unlab}, \n        epochs = epochs, batch_size= batch_size)\n\n# Extract encoder part\nlayer_name = model.layers[1].name\nlayer_output = model.get_layer(layer_name).output\nencoder = models.Model(inputs=model.input, outputs=layer_output)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(18,7))\n# plot loss\nplt.title('Mask Loss')\nplt.plot(encoder_history.history['mask_loss'], color='orange', label='Mask Loss')\nplt.plot(encoder_history.history['feature_loss'], color='red', label='Feature Loss')\nplt.legend();","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mlp_parameters = dict()\nmlp_parameters['hidden_dim'] = 256\nmlp_parameters['epochs'] = 1000\nmlp_parameters['activation'] = 'sigmoid'\nmlp_parameters['batch_size'] = 128\n\nx_train_hat = encoder.predict(x_train)\nx_test_hat = encoder.predict(x_test)\n      \ny_test_hat, MLP_history, acc = mlp(x_train_hat, y_train, x_test_hat, mlp_parameters)\n\nprint('VIME-Self Accuracy: ' + str(np.round(acc,2)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(18,7))\n# plot loss\nplt.subplot(121)\nplt.title('Cross Entropy Loss')\nplt.plot(MLP_history.history['loss'], color='blue', label='train')\nplt.plot(MLP_history.history['val_loss'], color='orange', label='test')\nplt.legend()\n\n# plot accuracy\nplt.subplot(122)\nplt.title('Classification Accuracy')\nplt.plot(MLP_history.history['acc'], color='blue', label='train')\nplt.plot(MLP_history.history['val_acc'], color='orange', label='test')\nplt.legend();","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}